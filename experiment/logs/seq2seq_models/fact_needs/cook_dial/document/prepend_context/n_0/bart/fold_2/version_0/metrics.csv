train_loss,epoch,step,val_loss,val_qa_answer_f1,val_qa_bert_score,val_qa_em,val_qa_sas,test_loss,test_avg_qa_answer_f1,test_avg_qa_bert_score,test_avg_qa_em,test_avg_qa_sas
1.163821816444397,0,9,,,,,,,,,,
0.8493158221244812,0,19,,,,,,,,,,
0.5999997854232788,0,29,,,,,,,,,,
,0,32,0.47668370604515076,0.20747585594654083,0.776458203792572,0.09649122506380081,0.1659250259399414,,,,,
0.6627642512321472,1,39,,,,,,,,,,
0.587497353553772,1,49,,,,,,,,,,
0.7670043706893921,1,59,,,,,,,,,,
,1,65,0.38011637330055237,0.2879575192928314,0.7991359233856201,0.19298245012760162,0.2335195541381836,,,,,
0.8177211284637451,2,69,,,,,,,,,,
0.5342076420783997,2,79,,,,,,,,,,
0.5603305697441101,2,89,,,,,,,,,,
,2,98,0.3680509328842163,0.29369431734085083,0.8291001915931702,0.2017543911933899,0.301483154296875,,,,,
0.5718167424201965,3,99,,,,,,,,,,
0.425983190536499,3,109,,,,,,,,,,
0.42758747935295105,3,119,,,,,,,,,,
0.40084800124168396,3,129,,,,,,,,,,
,3,131,0.35077032446861267,0.3672569990158081,0.8492204546928406,0.25438597798347473,0.34710693359375,,,,,
0.5313251614570618,4,139,,,,,,,,,,
0.47460052371025085,4,149,,,,,,,,,,
0.5181453227996826,4,159,,,,,,,,,,
,4,164,0.3410489559173584,0.3709818422794342,0.8568859696388245,0.2631579041481018,0.402008056640625,,,,,
,5,165,,,,,,0.3410489559173584,0.3709818422794342,0.8568859696388245,0.2631579041481018,0.402008056640625
